# Hyperliquid Auto Trade - Copy Trading Platform

A comprehensive copy trading platform for Hyperliquid that discovers successful traders through real-time WebSocket streams, tracks their positions using batched API calls, and provides a leaderboard with performance metrics. **Linux-native** and **rate limiting optimized** for production use.

## ğŸ—ï¸ Architecture Overview

The application consists of **4 separate services** managed by a Linux process manager:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hyperliquid    â”‚    â”‚   Service 1:         â”‚    â”‚   PostgreSQL    â”‚
â”‚  WebSocket      â”‚â—„â”€â”€â–ºâ”‚   Discovery Service  â”‚â”€â”€â”€â–ºâ”‚   Database      â”‚
â”‚  (Real-time)    â”‚    â”‚   (Standalone)       â”‚    â”‚   (Traders)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  Redis Pub/Sub  â”‚â—„â”€â”€â–ºâ”‚   Service 2:         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Real-time      â”‚    â”‚   Celery Worker      â”‚
â”‚  Events         â”‚    â”‚   (Batch Tracking)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚   Service 3:         â”‚
        â”‚               â”‚   Celery Beat        â”‚
        â”‚               â”‚   (Task Scheduler)   â”‚
        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â–¼               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   Service 4:    â”‚
â”‚  WebSocket      â”‚â—„â”€â”€â–ºâ”‚   FastAPI Web   â”‚
â”‚  Clients        â”‚    â”‚   Server        â”‚
â”‚  (/ws/v1/updates) â”‚   â”‚   (API + UI)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ Linux Process Management System

**Process Manager** (`process_manager.py`):

- **Linux-native**: Uses `os.setsid` process groups and `SIGTERM`/`SIGKILL` signals
- **Service orchestration**: Manages all 4 services with dependency handling
- **Auto-recovery**: Restarts crashed services automatically (up to 5 attempts)
- **Health monitoring**: Real-time monitoring with status display every 30 seconds
- **Graceful shutdown**: Clean termination of process trees with proper signal handling
- **Centralized logging**: Individual log files for each service in `logs/` directory

### Core Components

1. **WebSocket Discovery Service** (Standalone): Real-time trader discovery via WebSocket streams
2. **Celery Worker**: Batched trader position tracking with configurable concurrency (4 workers)
3. **Celery Beat Scheduler**: Manages periodic task execution (tracking every 75s, leaderboard every 10min)
4. **FastAPI Web Server**: Rate-safe REST API and real-time WebSocket distribution

## ğŸ“‹ Prerequisites

- Python 3.8+
- Docker and Docker Compose
- PostgreSQL 15+
- Redis 7+

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone <your-repo-url>
cd auto-trade-hyperliquid

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Configuration

Copy and configure your environment file:

```bash
cp .env.example .env
```

Edit `.env` with your settings:

```env
# Database settings
DATABASE_URL=postgresql://hyperliquid_user:hyperliquid_password@localhost:5432/hyperliquid_db

# Redis settings
REDIS_URL=redis://localhost:6379

# Hyperliquid API settings
HYPERLIQUID_API_URL=https://api.hyperliquid.xyz/info
HYPERLIQUID_PRIVATE_KEY=your_private_key_here  # For future trading features
HYPERLIQUID_WALLET_ADDRESS=your_wallet_address_here

# Popular coins to track (comma-separated)
POPULAR_COINS=BTC,ETH,SOL,AVAX,ARB,OP,MATIC

# Task configuration (Rate Limiting Optimized)
BATCH_SIZE=50
WEBSOCKET_URL=wss://api.hyperliquid.xyz/ws

# Celery settings
CELERY_BROKER_URL=redis://localhost:6379
CELERY_RESULT_BACKEND=redis://localhost:6379

# Application settings
DEBUG=False
SECRET_KEY=your-secret-key-change-this-in-production
```

### 3. Start Infrastructure

Start PostgreSQL and Redis using Docker:

```bash
docker-compose up -d
```

### 4. Initialize Database

Create the database tables:

```bash
python init_db.py
```

### 5. Start All Services (Recommended)

**Option A: Process Manager (Recommended)**

Start all services with automatic management:

```bash
# Linux startup script
chmod +x start_all_services.sh
./start_all_services.sh

# Or directly with Python
python process_manager.py
```

**Option B: Manual Service Startup**

If you prefer to run services manually in separate terminals:

```bash
# Terminal 1 - WebSocket Discovery Service
python start_discovery_service.py

# Terminal 2 - Celery Worker
python -m celery -A app.services.celery_app worker --loglevel=info --concurrency=4

# Terminal 3 - Celery Beat Scheduler
python -m celery -A app.services.celery_app beat --loglevel=info

# Terminal 4 - FastAPI Web Server
python run.py
```

### 6. Access the Application

- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Leaderboard**: http://localhost:8000/api/v1/leaderboard
- **Service Logs**: Check `logs/` directory for individual service logs

## ğŸ› ï¸ Process Management

### Service Control Commands

**Using the Process Manager:**

```bash
# Start all services
python process_manager.py

# View service logs
python service_control.py logs websocket-discovery
python service_control.py logs celery-worker
python service_control.py logs celery-beat
python service_control.py logs fastapi-server

# Check service status (within process manager)
# Status is displayed every 30 seconds automatically
```

**Individual Service Management:**

```bash
# Start individual services
python service_control.py start websocket-discovery
python service_control.py start celery-worker

# View logs for specific service
python service_control.py logs websocket-discovery
```

### Service Dependencies

The process manager handles service dependencies automatically:

1. **WebSocket Discovery Service** starts first (no dependencies)
2. **Celery Worker** starts second (depends on Redis/Database)
3. **Celery Beat Scheduler** starts third (depends on Celery Worker)
4. **FastAPI Web Server** starts last (depends on all data services)

### Log Files

All services log to individual files in the `logs/` directory:

```
logs/
â”œâ”€â”€ process_manager.log      # Process manager activity
â”œâ”€â”€ websocket-discovery.log  # WebSocket service logs
â”œâ”€â”€ websocket-discovery.error.log
â”œâ”€â”€ celery-worker.log        # Celery worker logs
â”œâ”€â”€ celery-worker.error.log
â”œâ”€â”€ celery-beat.log          # Celery beat scheduler logs
â”œâ”€â”€ celery-beat.error.log
â”œâ”€â”€ fastapi-server.log       # FastAPI web server logs
â””â”€â”€ fastapi-server.error.log
```

### Process Manager Features

- **Automatic Restart**: Services are restarted automatically if they crash (up to 5 attempts)
- **Dependency Management**: Services start in correct order based on dependencies
- **Health Monitoring**: Monitors service health every 10 seconds
- **Graceful Shutdown**: Handles Ctrl+C and shutdown signals properly
- **Service Status**: Displays real-time status every 30 seconds
- **Resource Tracking**: Shows PID, uptime, and restart count for each service

## ğŸ“Š Database Schema

### Tables Overview

```sql
-- Traders table: Stores discovered trader information
CREATE TABLE traders (
    id SERIAL PRIMARY KEY,
    address VARCHAR(42) UNIQUE NOT NULL,
    first_seen_at TIMESTAMP,
    last_tracked_at TIMESTAMP,  -- CRITICAL: Indexed for batching queue
    is_active BOOLEAN DEFAULT true
);

-- Index for efficient batch processing (queue management)
CREATE INDEX idx_traders_last_tracked_batching
ON traders(last_tracked_at ASC NULLS FIRST)
WHERE is_active = true;

-- User state history: Stores snapshots of trader positions
CREATE TABLE user_state_history (
    id SERIAL PRIMARY KEY,
    trader_id INTEGER REFERENCES traders(id),
    state_data JSONB NOT NULL,  -- Raw API response
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Trade events: Parsed position changes
CREATE TABLE trade_events (
    id SERIAL PRIMARY KEY,
    trader_id INTEGER REFERENCES traders(id),
    timestamp TIMESTAMP NOT NULL,
    event_type VARCHAR(50) NOT NULL,  -- position_opened, position_closed, position_increased, etc.
    details JSONB NOT NULL  -- { coin, previous_size, current_size, size_change, ... }
);

-- Leaderboard metrics: Calculated performance data
CREATE TABLE leaderboard_metrics (
    id SERIAL PRIMARY KEY,
    trader_id INTEGER REFERENCES traders(id),
    account_age_days INTEGER DEFAULT 0,
    total_volume_usd DECIMAL(20,8) DEFAULT 0,
    win_rate DECIMAL(5,4) DEFAULT 0,
    avg_risk_ratio DECIMAL(10,6) DEFAULT 0,
    max_drawdown DECIMAL(5,4) DEFAULT 0,
    max_profit_usd DECIMAL(20,8) DEFAULT 0,
    max_loss_usd DECIMAL(20,8) DEFAULT 0,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ”„ Application Flow (Linux-Native & Rate-Limited)

### Service 1: Real-time Trader Discovery (Standalone WebSocket Service)

**No longer a Celery task** - Runs as independent process managed by ProcessManager:

```bash
# Launched by: start_discovery_service.py
# Managed by: process_manager.py
```

1. **WebSocket Connection**: Maintains persistent connection to `wss://api.hyperliquid.xyz/ws`

   ```python
   # WebSocket subscription for each popular coin
   subscription_msg = {
       "method": "subscribe",
       "subscription": {
           "type": "trades",
           "coin": "BTC"  # BTC, ETH, SOL, AVAX, ARB, OP, MATIC
       }
   }
   ```

2. **Real-time Trade Processing**: Processes incoming trade messages instantly

   ```json
   {
     "channel": "trades",
     "data": [
       { "user": "0x1234...", "sz": "1.5", "px": "45000", "coin": "BTC", ... },
       { "user": "0x5678...", "sz": "0.8", "px": "45010", "coin": "BTC", ... }
     ]
   }
   ```

3. **Trader Discovery**: Creates new `Trader` records for unknown addresses
   - **Rate Limiting**: âœ… **Zero API weight cost** - pure WebSocket data
   - **Benefits**: Immediate discovery, no polling delays, unlimited scalability

### Service 2: Batched Position Tracking (Celery Task)

```python
# app/services/tasks/tracking_task.py - task_track_traders_batch()
# Scheduled: Every 75 seconds (rate-safe interval)
```

1. **Queue-Based Selection**: Uses database index for efficient batch selection

   ```sql
   SELECT * FROM traders
   WHERE is_active = true
   ORDER BY last_tracked_at ASC NULLS FIRST
   LIMIT 50;  -- Configurable BATCH_SIZE
   ```

2. **Batched API Calls**: Processes exactly 50 traders per batch

   ```python
   # For each trader in batch
   current_state = await hyperliquid_client.get_user_state(trader.address)
   # API Weight: 2 per trader Ã— 50 traders = 100 weight per batch
   # Total with safety margin: ~1000 weight per 75 seconds = 800 weight/minute
   ```

3. **Position Change Detection**: Compares with previous state to detect events

   ```python
   # Enhanced position change detection
   if prev_size == 0 and curr_size != 0:
       event_type = "OPEN_POSITION"
   elif prev_size != 0 and curr_size == 0:
       event_type = "CLOSE_POSITION"
   elif abs(curr_size) > abs(prev_size):
       event_type = "INCREASE_POSITION"
   elif abs(curr_size) < abs(prev_size):
       event_type = "DECREASE_POSITION"
   ```

4. **Queue Management**: Updates `last_tracked_at` to send trader to back of queue

   ```python
   trader.last_tracked_at = datetime.utcnow()  # Critical for queue rotation
   ```

5. **Event Storage & Broadcasting**:
   - Saves `TradeEvent` to PostgreSQL with detailed position data
   - Publishes to Redis pub/sub channel `"trade_events"` for real-time updates
   - Updates `UserStateHistory` with new state snapshot

### Service 3: Leaderboard Calculation (Celery Task)

```python
# app/services/tasks/leaderboard_task.py - task_calculate_leaderboard()
# Scheduled: Every 10 minutes
```

1. **Account Age**: `(datetime.utcnow() - trader.first_seen_at).days`

2. **Total Volume**: Sums notional values from position events

   ```python
   for event in trade_events:
       if event.event_type == 'position_opened':
           details = event.details
           size = float(details['current_size'])
           entry_price = float(details.get('entry_price', 0))
           total_volume += abs(size) * entry_price
   ```

3. **Metric Storage**: Updates `LeaderboardMetric` table with calculated performance data

## ğŸ¯ Rate Limiting Compliance

### âœ… **Safe Operations (Zero Risk)**

- **WebSocket Discovery**: No API weight cost, unlimited trader discovery
- **Database Queries**: Local operations, no external API calls
- **Redis Operations**: Local caching and pub/sub, no rate limits
- **FastAPI Endpoints**: Serve cached data only, no direct API calls

### ğŸ”„ **Rate-Limited Operations (Controlled)**

- **Batch Tracking**: 50 traders Ã— 20 weight = 1000 weight per 75 seconds
- **Theoretical Rate**: 800 weight/minute (33% under 1200 limit)
- **Safety Margin**: 400 weight/minute buffer for burst capacity
- **Queue Management**: Ensures all traders get tracked fairly over time

### ğŸ“Š **Performance Metrics**

- **Discovery Latency**: Real-time (WebSocket instant notifications)
- **Tracking Coverage**: All active traders rotated through queue system
- **Update Frequency**: Position updates every 75 seconds per trader
- **Scalability**: Handles thousands of traders without rate limit concerns

## ğŸŒ API Endpoints (Rate-Safe Design)

### REST API

| Endpoint               | Method | Description                      | Rate Impact | Caching          |
| ---------------------- | ------ | -------------------------------- | ----------- | ---------------- |
| `/`                    | GET    | Welcome message                  | âœ… None     | None             |
| `/health`              | GET    | Health check                     | âœ… None     | None             |
| `/api/v1/leaderboard`  | GET    | Cached leaderboard with sorting  | âœ… None     | 5min Redis       |
| `/leaderboard`         | GET    | Legacy leaderboard endpoint      | âœ… None     | Via new endpoint |
| `/traders`             | GET    | List all tracked traders         | âœ… None     | Database only    |
| `/traders/{id}/events` | GET    | Trade events for specific trader | âœ… None     | Database only    |
| `/api/v1/cache/clear`  | GET    | Clear leaderboard cache          | âœ… None     | Admin only       |
| `/api/v1/stats`        | GET    | System statistics                | âœ… None     | Real-time        |

**ğŸš« REMOVED (Rate-Limited Endpoints):**

- ~~`POST /traders/{address}/track`~~ - Previously triggered direct API calls

### Query Parameters

**Leaderboard Sorting:**

```bash
GET /api/v1/leaderboard?sort_by=total_volume_usd&order=desc
GET /api/v1/leaderboard?sort_by=win_rate&order=asc
```

Available sort fields:

- `win_rate` (default)
- `total_volume_usd`
- `account_age_days`
- `max_profit_usd`
- `max_loss_usd`
- `avg_risk_ratio`
- `max_drawdown`

### WebSocket API (Real-time Distribution)

**Real-time Trade Updates:**

```javascript
const ws = new WebSocket("ws://localhost:8000/ws/v1/updates");

ws.onopen = function () {
  console.log("Connected to real-time updates");
};

ws.onmessage = function (event) {
  const data = JSON.parse(event.data);

  if (data.type === "connection") {
    console.log("Connection confirmed:", data.message);
  } else if (data.type === "trade_event") {
    console.log("New trade event:", data.data);
    // Handle real-time position change
  }
};
```

**WebSocket Message Types:**

1. **Connection Confirmation:**

   ```json
   {
     "type": "connection",
     "message": "Connected to real-time updates feed",
     "timestamp": "2025-08-05T10:30:00.000Z"
   }
   ```

2. **Trade Event (Enhanced):**
   ```json
   {
     "type": "trade_event",
     "data": {
       "id": 12345,
       "trader_id": 67,
       "trader_address": "0x1234567890abcdef...",
       "timestamp": "2025-08-05T10:30:15.123Z",
       "event_type": "position_opened",
       "details": {
         "coin": "BTC",
         "previous_size": 0,
         "current_size": 1.5,
         "size_change": 1.5,
         "previous_position": {},
         "current_position": {
           "coin": "BTC",
           "szi": "1.5",
           "entryPx": "45000.0"
         }
       }
     },
     "timestamp": "2025-08-05T10:30:15.500Z"
   }
   ```

### System Statistics Endpoint

**GET `/api/v1/stats`** - Monitor system health:

```json
{
  "database": {
    "total_traders": 1247,
    "active_traders": 892,
    "total_trade_events": 15632
  },
  "websocket": {
    "active_connections": 12
  },
  "cache": {
    "redis_connected": true
  },
  "timestamp": "2025-08-05T10:30:00.000Z"
}
```

2. **Trade Event:**
   ```json
   {
     "type": "trade_event",
     "data": {
       "id": 123,
       "trader_id": 45,
       "trader_address": "0x1234...",
       "timestamp": "2025-08-03T10:30:00.000Z",
       "event_type": "OPEN_POSITION",
       "details": {
         "coin": "BTC",
         "size": "1.5",
         "side": "LONG",
         "entry_price": "45000"
       }
     },
     "timestamp": "2025-08-03T10:30:00.000Z"
   }
   ```

## ğŸ”§ Configuration

### Environment Variables (Rate-Limited Optimized)

| Variable                | Description                      | Example                                    | Rate Impact |
| ----------------------- | -------------------------------- | ------------------------------------------ | ----------- |
| `DATABASE_URL`          | PostgreSQL connection string     | `postgresql://user:pass@localhost:5432/db` | âœ… None     |
| `REDIS_URL`             | Redis connection string          | `redis://localhost:6379`                   | âœ… None     |
| `HYPERLIQUID_API_URL`   | API base URL                     | `https://api.hyperliquid.xyz/info`         | âœ… None     |
| `POPULAR_COINS`         | Coins to track (comma-separated) | `BTC,ETH,SOL,AVAX`                         | âœ… None     |
| `BATCH_SIZE`            | Traders per batch (rate control) | `50`                                       | ğŸ”„ Manages  |
| `WEBSOCKET_URL`         | WebSocket endpoint URL           | `wss://api.hyperliquid.xyz/ws`             | âœ… None     |
| `CELERY_BROKER_URL`     | Celery broker URL                | `redis://localhost:6379`                   | âœ… None     |
| `CELERY_RESULT_BACKEND` | Celery result backend            | `redis://localhost:6379`                   | âœ… None     |
| `DEBUG`                 | Debug mode                       | `False`                                    | âœ… None     |
| `SECRET_KEY`            | Application secret key           | `your-secret-key`                          | âœ… None     |

### Celery Task Schedule (Current Configuration)

```python
# app/services/celery_app.py
beat_schedule = {
    'track-traders-batch': {
        'task': 'app.services.tasks.tracking_task.task_track_traders_batch',
        'schedule': 75.0,   # 75 seconds (rate-safe batching)
    },
    'calculate-leaderboard': {
        'task': 'app.services.tasks.leaderboard_task.task_calculate_leaderboard',
        'schedule': 600.0,  # 10 minutes (frequent updates)
    },
}
```

**Note**: WebSocket discovery service now runs standalone (not as a Celery task)

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Configure environment variables:
   Copy `.env` and update the values:

```bash
cp .env .env.local
# Edit .env.local with your actual configuration
```

## Configuration

Update the `.env` file with your configuration:

- `DATABASE_URL`: PostgreSQL connection string
- `REDIS_URL`: Redis connection string
- `HYPERLIQUID_API_URL`: Hyperliquid API endpoint
- `HYPERLIQUID_PRIVATE_KEY`: Your wallet private key (keep secure!)
- `HYPERLIQUID_WALLET_ADDRESS`: Your wallet address

## Running the Application

### Development Mode

1. Start the FastAPI server:

```bash
python run.py
```

2. Start Celery worker (in a separate terminal):

```bash

```

3. Start Celery beat scheduler (in another terminal):

```bash
celery -A app.services.celery_app beat --loglevel=info
```

### Production Mode

Use a process manager like Supervisor or Docker to manage the services.

## API Endpoints

- `GET /`: Root endpoint
- `GET /health`: Health check
- More endpoints will be added for trading functionality

## Database Setup

1. Install PostgreSQL and create a database
2. Update the `DATABASE_URL` in your `.env` file
3. Run database migrations (to be implemented with Alembic)

## Redis Setup

1. Install Redis
2. Update the `REDIS_URL` in your `.env` file

## ğŸ“ˆ Performance Features (Rate-Limited Optimized)

### Rate Limiting Compliance

- **WebSocket Discovery**: âœ… Zero API weight cost, unlimited trader discovery
- **Batched Tracking**: ğŸ”„ 800 weight/minute (33% under 1200 limit) with 400 weight buffer
- **FastAPI Endpoints**: âœ… No direct API calls, serves cached data only
- **Queue Management**: Database indexes ensure efficient trader rotation

### Redis Caching

- **Leaderboard Cache**: 5-minute TTL reduces database load
- **Cache Keys**: `leaderboard_cache:{sort_by}:{order}`
- **Cache Hit Rate**: ~95% for frequently accessed leaderboards
- **Pub/Sub**: Real-time event distribution without API calls

### Database Optimization

- **Critical Index**: `idx_traders_last_tracked_batching` for queue management
- **JSONB Storage**: Efficient position data storage and querying
- **Batch Processing**: Optimized queries for 50-trader batches

### Real-time Updates

- **Redis Pub/Sub**: Zero-latency event broadcasting
- **WebSocket Connections**: Persistent connections for real-time data
- **Event Filtering**: Only position changes generate events

### Database Optimization

- **JSONB Fields**: Efficient storage and querying of API responses
- **Indexes**: Optimized queries on trader addresses and timestamps
- **Connection Pooling**: SQLAlchemy connection management

## ğŸ› ï¸ Development

### Code Structure

```
app/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # FastAPI application and endpoints
â”œâ”€â”€ core/
â”‚   â””â”€â”€ config.py            # Pydantic settings management
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy setup and session management
â”‚   â””â”€â”€ models.py            # Database models (Trader, TradeEvent, etc.)
â””â”€â”€ services/
    â”œâ”€â”€ celery_app.py        # Celery configuration and scheduling
    â”œâ”€â”€ discovery_service.py # Standalone WebSocket discovery service
    â”œâ”€â”€ hyperliquid_client.py # Hyperliquid API client
    â””â”€â”€ tasks/
        â”œâ”€â”€ tracking_task.py # Trader position tracking
        â”œâ”€â”€ leaderboard_task.py # Leaderboard calculation
        â””â”€â”€ utils.py         # Shared utilities

# Root files
â”œâ”€â”€ process_manager.py       # Linux process manager (main service orchestrator)
â”œâ”€â”€ start_discovery_service.py # Discovery service launcher
â”œâ”€â”€ start_all_services.sh    # Linux startup script
â”œâ”€â”€ run.py                   # FastAPI server startup
â”œâ”€â”€ init_db.py               # Database initialization
â”œâ”€â”€ docker-compose.yml       # Infrastructure services
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ Makefile                 # Development commands
```

### Key Technologies

- **FastAPI**: Modern, fast web framework with automatic API docs
- **SQLAlchemy 2.0**: Modern ORM with async support and type hints
- **Celery**: Distributed task queue for background processing
- **Redis**: In-memory data store for caching and pub/sub
- **PostgreSQL**: Robust relational database with JSONB support
- **Pydantic**: Data validation and settings management
- **httpx**: Modern async HTTP client

### Development Commands

```bash
# Start infrastructure
make docker-up

# Install dependencies
make install

# Start development server
make run

# Start Celery worker
make worker

# Start Celery beat scheduler
make beat

# Clean up temporary files
make clean
```

## ğŸ› Troubleshooting

### Common Issues

1. **Connection Errors**:

   ```bash
   # Check if services are running
   docker-compose ps

   # Restart services
   docker-compose restart
   ```

2. **Database Issues**:

   ```bash
   # Recreate database
   python init_db.py

   # Check connection
   psql postgresql://hyperliquid_user:hyperliquid_password@localhost:5432/hyperliquid_db
   ```

3. **Celery Tasks Not Running**:

   ```bash
   # Check worker status
   celery -A app.services.celery_app inspect active

   # Check beat schedule
   celery -A app.services.celery_app inspect scheduled
   ```

4. **API Errors**:

   ```bash
   # Check logs
   tail -f logs/app.log

   # Test API endpoints
   curl http://localhost:8000/health
   ```

### Logging

The application uses structured logging:

```python
import logging
logger = logging.getLogger(__name__)

# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
logger.info("Task completed successfully")
logger.error("Error occurred: %s", error_message)
```

## ğŸš€ Production Deployment

### Docker Production Setup

1. **Create Production Environment**:

   ```bash
   cp .env .env.production
   # Update production values
   ```

2. **Build Production Images**:

   ```dockerfile
   FROM python:3.11-slim
   COPY requirements.txt .
   RUN pip install -r requirements.txt
   COPY app/ /app/
   ```

3. **Deploy with Docker Compose**:
   ```yaml
   version: "3.8"
   services:
     web:
       build: .
       ports:
         - "8000:8000"
       environment:
         - DATABASE_URL=postgresql://...
         - REDIS_URL=redis://...
   ```

### Monitoring

- **Health Checks**: `/health` endpoint
- **Metrics**: Celery task monitoring
- **Logging**: Centralized log aggregation
- **Performance**: Redis cache hit rates

## ğŸ” Example Usage

### 1. Start the System

```bash
# Terminal 1: Start infrastructure
docker-compose up -d

# Terminal 2: Initialize database
python init_db.py

# Terminal 3: Start web server
python run.py

# Terminal 4: Start Celery worker
celery -A app.services.celery_app worker --loglevel=info

# Terminal 5: Start Celery beat scheduler
celery -A app.services.celery_app beat --loglevel=info
```

### 2. API Usage Examples

**Get Leaderboard:**

```bash
curl "http://localhost:8000/api/v1/leaderboard?sort_by=total_volume_usd&order=desc"
```

**Track a Specific Trader:**

```bash
curl -X POST "http://localhost:8000/traders/0x1234567890abcdef/track"
```

**Get Trader Events:**

```bash
curl "http://localhost:8000/traders/1/events"
```

### 3. WebSocket Client Example

```html
<!DOCTYPE html>
<html>
  <head>
    <title>Hyperliquid Live Trades</title>
  </head>
  <body>
    <div id="trades"></div>
    <script>
      const ws = new WebSocket("ws://localhost:8000/ws/v1/trades");
      const tradesDiv = document.getElementById("trades");

      ws.onmessage = function (event) {
        const data = JSON.parse(event.data);
        if (data.type === "trade_event") {
          const trade = data.data;
          tradesDiv.innerHTML += `
                    <div>
                        <strong>${trade.event_type}</strong>: 
                        ${trade.details.coin} ${trade.details.size} 
                        @ ${trade.details.entry_price}
                        (${trade.trader_address})
                    </div>
                `;
        }
      };
    </script>
  </body>
</html>
```

## Security Notes

- Keep your private keys secure and never commit them to version control
- Use environment variables for sensitive configuration
- Consider using encrypted storage for private keys in production

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ¯ Next Steps

1. **Enhanced Metrics**: Add more sophisticated trading metrics
2. **Copy Trading**: Implement actual position copying
3. **User Authentication**: Add user accounts and API keys
4. **Advanced Filtering**: More leaderboard filter options
5. **Mobile App**: React Native mobile application
6. **Machine Learning**: Predictive trader scoring

## ğŸ“Š Monitoring & Health Checks

### System Statistics

Monitor the application through the `/api/v1/stats` endpoint:

```bash
curl http://localhost:8000/api/v1/stats
```

### Key Metrics to Monitor

1. **Rate Limiting Health**:

   - API weight usage should stay under 800/minute average
   - WebSocket connection stability
   - Batch processing success rates

2. **Database Performance**:

   - Active trader count and growth
   - Trade event creation rate
   - Queue rotation efficiency (last_tracked_at distribution)

3. **Real-time System**:
   - WebSocket connection count
   - Redis pub/sub message throughput
   - Cache hit rates

### Logging Levels

```bash
# Set log levels for monitoring
export LOG_LEVEL=INFO  # or DEBUG for detailed monitoring
```

### Health Check Endpoints

- `GET /health` - Basic application health
- `GET /api/v1/stats` - Detailed system statistics
- WebSocket connection count via stats endpoint

---

**Happy Trading! ğŸš€**

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## License

[Add your license here]
